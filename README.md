# Automatic-Smart-Shot
Automatic is a basketball shot tracker on Watch OS that uses motion sensor artificial intelligence to recognize personal jump shots. It then returns basketball related metrics to the user who can use it as feedback to train themselves. For example, if the user takes a shot with a 49 degree x-angle and misses it, and shoots with a 45 degree angle and makes it, we can tell the user where to try to put their arc. With Watch OS, we as developers can get tons of data that will come in handy with an app like this.

Apple's watch and iphone products both possess powerful motion sensor tools such as accelerometers, gyrometers, magnetometers, and altimeters that can run at up to 100 Hz. All XCode developers have access to these data points in their programs. Being that I love basketball, When I was first introduced to the idea of developing an app with this data, I thought , "Why not make an apple watch app that could track the motion of a basketball shot?".

Since then, I've dedicated most of my free time to figuring this problem out and it has been an absolute journey to say the least. Through several weeks of thinking this project out, I decided the best route to go down was machine learning. If I could feed an AI data points over periods of time, I could train it to recognize specific movements, differentiating between shots and no shots, and gathering the motion data within that the timeframe of the shot. At the time, I knew nothing about machine learning. Lucky for me, XCode comes with a free "Create ML" machine learning tool that is very easy to learn. 

After weeks of figuring the create ML out, I had finally made an AI that could vaguely recognize the motion of a basketball shot. However, there were some major flaws. 1) The AI was personalized to my jumpshot only. 2)The AI could not fully encapsulate all of the data 100% of the time. 3)The AI would sometimes not pick up on the shot movement at all. After talking these problems out with several people, I realized I was relying way too much on the algorithms of the AI and not diving deep enough into the data itself. In order to make a successful app that recognizes a shot, I first needed to figure out how the motion sensors reacted to the initiation of a shot motion, so that maybe I could find alternative ways to capture my data.

So, I retraced my steps and decided to complete my first prototype. Prototype 1 of Automatic : Smart Shot's sole purpose was to capture motion data for three seconds after a button was pressed. Then, this data would be saved to a class and exported to a csv file on the background of the xCode project. To clean up my data, I rounded all values to the nearest hundereth. This prototype allowed me to test shot movements as a developer, and to further look into how the accelerometer and gyrometer reacted when a shot motion occured. 
